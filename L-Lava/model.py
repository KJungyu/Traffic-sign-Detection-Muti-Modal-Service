# model.py
from transformers import LlavaForConditionalGeneration, LlavaProcessor

def load_model(model_name="bczhou/tiny-llava-v1-hf"):
    # 1) ëª¨ë¸ ë¡œë“œ
    model = LlavaForConditionalGeneration.from_pretrained(model_name)
    # 2) LlavaProcessor ë¡œ ìƒì„±
    processor = LlavaProcessor.from_pretrained(model_name)

    # 3) vision_configì—ì„œ patch_size(dimension) ê°€ì ¸ì˜¤ê¸°
    model_patch_size = model.config.vision_config.patch_size

    # â”€â”€ (A) processor ìì²´ì— patch_size ì†ì„±ì´ ì—†ìœ¼ë©´ ê°•ì œë¡œ ìƒì„±í•©ë‹ˆë‹¤.
    setattr(processor, "patch_size", model_patch_size)
    print(f"âœ… processor.patch_sizeë¥¼ {model_patch_size}ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.")

    # â”€â”€ (B) image_processor.patch_sizeë¥¼ ë¬´ì¡°ê±´ 14ë¡œ ì„¤ì •
    #     (ë”•ì…”ë„ˆë¦¬ë‚˜ ê°ì²´ êµ¬ë¶„ ì—†ì´, í•´ë‹¹ ì†ì„±ì´ ìˆìœ¼ë©´ ë®ì–´ì”Œì›ë‹ˆë‹¤.)
    try:
        setattr(processor.image_processor, "patch_size", model_patch_size)
        print(f"âœ… processor.image_processor.patch_sizeë¥¼ {model_patch_size}ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        # ë³´í†µ image_processorê°€ dict êµ¬ì¡°ê°€ ì•„ë‹ˆë¼ ê°„ë‹¨í•œ ê°ì²´ì´ë¯€ë¡œ ìœ„ ì½”ë“œê°€ ë™ì‘í•©ë‹ˆë‹¤.
        print(f"âš ï¸ image_processor.patch_size ì„¤ì • ì‹¤íŒ¨: {e}")

    # â”€â”€ ìµœì¢… ìƒíƒœ ì¶œë ¥ â”€â”€
    print("ğŸ” ìµœì¢… Processor ìƒíƒœ:")
    print(f"  - processor.patch_size: {getattr(processor, 'patch_size', None)}")
    print(f"  - image_processor.patch_size: {getattr(processor.image_processor, 'patch_size', None)}")

    return model, processor



